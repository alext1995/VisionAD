{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8715cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alext\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "from algos.model_wrapper import ModelWrapper\n",
    "from wrapper.wrapper import run_metrics\n",
    "from data.configure_dataset import load_dataset\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f62e50",
   "metadata": {},
   "source": [
    "### Algorithm code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3ce7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class WrapperRandom(ModelWrapper):\n",
    "    '''\n",
    "    This is a demonstration of a model which makes random predictions\n",
    "    Amend this as you wish to create a model which fits the VisionAD package\n",
    "    '''\n",
    "    def __init__(self, load_params=True, **kwargs):\n",
    "        super(ModelWrapper, self).__init__()\n",
    "        if load_params:\n",
    "            self.load_model_params(**kwargs)\n",
    "        self.default_segmentation = \"method_1\"\n",
    "        self.default_score = \"method_1\"\n",
    "        \n",
    "    def load_model_params(self, **params):\n",
    "        self.__name__ = \"Random\"\n",
    "        self.params = params\n",
    "        \n",
    "        print(\"Created model with:\\n\")\n",
    "        print(\"param1: \", self.params[\"param_1\"])\n",
    "        print(\"param2: \", self.params[\"param_2\"])\n",
    "        \n",
    "        # put these into class params if you wish, or just access the self.params dictionary\n",
    "        self.param_1 = self.params[\"param_1\"]\n",
    "        self.param_2 = self.params[\"param_2\"]\n",
    "        \n",
    "    def train_one_epoch(self,):\n",
    "        print(\"Doing an epoch\") \n",
    "        for image, path, image_callback_info in self.dataloader_train:\n",
    "            self.seed_value = np.random.randint(1000)\n",
    "            np.random.seed(self.seed_value)\n",
    "            \n",
    "        ## image_callback_info is only relevant if you add a callback to the \n",
    "        ## dataloader_train. If you don't, you can ignore it\n",
    "        ## see the Synthetic anomalies section in the Readme for more information\n",
    "        \n",
    "    def eval_outputs_dataloader(self, dataloader, len_dataloader):\n",
    "        length = 0\n",
    "        for item, _ in dataloader:\n",
    "            length+=item.shape[0]\n",
    "\n",
    "        a_pixel_ret  = {\"method_1\":np.random.rand(length, 256, 256)>self.param_1, \n",
    "                        \"method_2\":np.random.rand(length, 256, 256)>self.param_2}\n",
    "        a_image_ret  = {\"method_1\":np.random.rand(length),\n",
    "                        \"method_2\":np.random.rand(length)}\n",
    "        return a_pixel_ret, a_image_ret\n",
    "    \n",
    "    def pre_eval_processing(self):\n",
    "        print(\"Running the pre-evaluation processing\")\n",
    "        \n",
    "        \n",
    "    def save_model(self, location):\n",
    "        self.save_params(location) # necessary code \n",
    "        # save other stuff here such as ml weight, e.g.\n",
    "        # torch.save(self.ml_model, os.path.join(location, \"model.pt\"))\n",
    "        torch.save(self.seed_value, os.path.join(location, \"model.pt\"))\n",
    "    \n",
    "    def load_model(self, location):\n",
    "        params = self.load_params(location)  # necessary code \n",
    "        self.load_model_params(**params)  # necessary code \n",
    "        # load other stuff here such as ml weight, e.g.\n",
    "        # self.ml_model.load_state_dict(torch.load(os.path.join(location, \"model.pt\")))\n",
    "        self.seed_value = torch.load(os.path.join(location, \"model.pt\"))\n",
    "        np.random.seed(self.seed_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e145e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_string = \"mvtec_bottle\"\n",
    "\n",
    "default_params = {\"param_1\": 0.5, \n",
    "                  \"param_2\": 0.7}\n",
    "\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99935ce5",
   "metadata": {},
   "source": [
    "### boilerplate testing code - change dataset here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c1e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from data.load_image_data import create_dataloaders, make_unnormalise\n",
    "device = \"cuda:0\"\n",
    "\n",
    "dataset = load_dataset(dataset_string)\n",
    "\n",
    "image_size = 256\n",
    "model_parameters = {\"model_params\": default_params,\n",
    "                    \"epochs\": epochs, # ignored in this notebook\n",
    "                    \"training_transformations\":  transforms.Compose([]),\n",
    "                    \"training_transformation_string\": \"transforms.Compose([])\",\n",
    "                    \"identical_transforms\": transforms.Compose([transforms.Resize((image_size, image_size), \n",
    "                                                                interpolation=Image.NEAREST),\n",
    "                                                                ]),\n",
    "                    \"batch_size\": 8,\n",
    "                    \"save_model_every_n_epochs\": None,\n",
    "                    \"save_heatmaps_n_epochs\": 0,\n",
    "                    \"evaluate_n_epochs\": 0,\n",
    "                    \"test_batch_size\": 8,\n",
    "                    \"use_gpu\": True,\n",
    "                    \"wandb\": False, \n",
    "                    }\n",
    "\n",
    "model_parameters[\"pre_pro_transforms\"] = transforms.Compose([transforms.Normalize(mean=dataset['mean'], \n",
    "                                                                                  std=dataset['std'])])\n",
    "\n",
    "dataloader_train, dataloader_regular_test, dataloader_novel_test = create_dataloaders(                                                 \n",
    "                                                        pre_pro_transforms=model_parameters[\"pre_pro_transforms\"], \n",
    "                                                        training_transformations=model_parameters[\"training_transformations\"],\n",
    "                                                        identical_transforms=model_parameters[\"identical_transforms\"],\n",
    "                                                        batch_size = model_parameters[\"batch_size\"],\n",
    "                                                        shuffle = True,\n",
    "                                                        device = device, \n",
    "                                                        unnormalise = make_unnormalise(mean=dataset['mean'], \n",
    "                                                                                       std=dataset['std']),\n",
    "                                                        test_batch_size = model_parameters[\"test_batch_size\"],\n",
    "                                                        **dataset)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b01c8b",
   "metadata": {},
   "source": [
    "### Testing running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e3d1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model with:\n",
      "\n",
      "param1:  0.5\n",
      "param2:  0.7\n",
      "\n",
      "Doing epoch: 0\n",
      "Doing an epoch\n",
      "\n",
      "Doing epoch: 1\n",
      "Doing an epoch\n",
      "\n",
      "Doing epoch: 2\n",
      "Doing an epoch\n",
      "\n",
      "Doing epoch: 3\n",
      "Doing an epoch\n",
      "\n",
      "Doing epoch: 4\n",
      "Doing an epoch\n",
      "\n",
      "Running the pre-evaluation processing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo_class = WrapperRandom(**default_params)\n",
    "algo_class.enter_dataloaders(dataloader_train, \n",
    "                             dataloader_regular_test, \n",
    "                             dataloader_novel_test)\n",
    "print(\"\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Doing epoch: {epoch}\")\n",
    "    algo_class.train_one_epoch()\n",
    "    print(\"\")\n",
    "# always ran before evaluation\n",
    "algo_class.pre_eval_processing()\n",
    "print(\"\")\n",
    "\n",
    "heatmap_set, score_set, target_set, path_set = algo_class.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24893d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Async metric time taken: 12.191307306289673\n",
      "\n",
      "Imagewise_AUC:\n",
      "\tmethod_1: 0.5349206349206349\n",
      "\tmethod_2: 0.5325396825396825\n",
      "Pixelwise_AUC:\n",
      "\tmethod_1: 0.5000606391814277\n",
      "\tmethod_2: 0.5002567781758736\n",
      "Pixelwise_AUPRO:\n",
      "Pixelwise_AUC_anom_only:\n",
      "\tmethod_1: 0.50013018464272\n",
      "\tmethod_2: 0.5002667856238572\n",
      "PL:\n",
      "\tmethod_1: 0.014705882352941176\n",
      "\tmethod_2: 0.058823529411764705\n",
      "\n",
      "Metric time taken:\n",
      "\n",
      "Imagewise_AUC: 0.006s\n",
      "Pixelwise_AUC: 3.3s\n",
      "Pixelwise_AUPRO: 0.046s\n",
      "Pixelwise_AUC_anom_only: 2.6s\n",
      "PL: 2.9s\n",
      "Not saved the metrics results\n"
     ]
    }
   ],
   "source": [
    "metric_list = [\"Imagewise_AUC\",\n",
    "               \"Pixelwise_AUC\",\n",
    "               \"Pixelwise_AUPRO\",\n",
    "               \"PL\",\n",
    "              ]\n",
    "metric_results = run_metrics(metric_list, heatmap_set, score_set, target_set, path_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7372f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_path = \"/mnt/faster0/adjt20/testing/creating_algo_demo_test\" # enter your own path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4c7a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test saving the model\n",
    "algo_class.save_model(save_load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f413f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model with:\n",
      "\n",
      "param1:  0.5\n",
      "param2:  0.7\n"
     ]
    }
   ],
   "source": [
    "# test loading the model from scratch\n",
    "algo_class = WrapperRandom(load_params=False) # the params are saved to the location so do not need to be entered\n",
    "algo_class.load_model(save_load_path)\n",
    "\n",
    "algo_class.enter_dataloaders(dataloader_train, \n",
    "                             dataloader_regular_test, \n",
    "                             dataloader_novel_test)\n",
    "\n",
    "# ready to test the model\n",
    "heatmap_set, score_set, target_set, path_set = algo_class.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6dacf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Async metric time taken: 12.237514972686768\n",
      "\n",
      "Imagewise_AUC:\n",
      "\tmethod_1: 0.5349206349206349\n",
      "\tmethod_2: 0.5325396825396825\n",
      "Pixelwise_AUC:\n",
      "\tmethod_1: 0.5001112591092877\n",
      "\tmethod_2: 0.5000728591046495\n",
      "Pixelwise_AUPRO:\n",
      "Pixelwise_AUC_anom_only:\n",
      "\tmethod_1: 0.5001818103420511\n",
      "\tmethod_2: 0.5000792122496205\n",
      "PL:\n",
      "\tmethod_1: 0.014705882352941176\n",
      "\tmethod_2: 0.058823529411764705\n",
      "\n",
      "Metric time taken:\n",
      "\n",
      "Imagewise_AUC: 0.0035s\n",
      "Pixelwise_AUC: 3.8s\n",
      "Pixelwise_AUPRO: 0.036s\n",
      "Pixelwise_AUC_anom_only: 3s\n",
      "PL: 3s\n",
      "Not saved the metrics results\n"
     ]
    }
   ],
   "source": [
    "metric_results = run_metrics(metric_list, heatmap_set, score_set, target_set, path_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e467c5",
   "metadata": {},
   "source": [
    "## Steps to implement this algorithm into the wrapper\n",
    "\n",
    "1. Amend the above class to create the algorithm\n",
    "2. Once complete, and the testing code works, enter the algorithm into\n",
    "    algos/{algo_name}/algo_class.py\n",
    "3. Enter the following into the algos/algo_class_list.py file:\n",
    "    ```\n",
    "    if algo_name.lower()==\"{algo_name}\".lower():\n",
    "        from algos.{algo_name}.algo_class import Wrapper{algo_name}\n",
    "        return Wrapper{algo_name}\n",
    "    ```    \n",
    "4. Enter the default model parameters into algos/{algo_name}/_defaultconfigs.py:\n",
    "    ```\n",
    "    {algo_name}_default_model_params = {}\n",
    "    ```    \n",
    "    \n",
    "5. Create a config file configs/{algo_name}/run_1.py which contains the following code:\n",
    "    ```\n",
    "    from torchvision import transforms\n",
    "    from PIL import Image\n",
    "    from algos.{algo_name}._defaultconfigs import {algo_name}_default_model_params\n",
    "    image_size = 256\n",
    "\n",
    "    model_list = []\n",
    "\n",
    "    model_list.append({\"algo_class_name\": \"{algo_name}\", \n",
    "                        \"model_params\": {algo_name}_default_model_params,\n",
    "                        \"epochs\": 50,\n",
    "                        \"training_transformations\":  transforms.Compose([]),\n",
    "                        \"training_transformation_string\": \"transforms.Compose([])\",\n",
    "                        \"identical_transforms\": transforms.Compose([transforms.Resize((image_size, image_size), \n",
    "                                                                    interpolation=Image.NEAREST),\n",
    "                                                                    ]),\n",
    "                        \"batch_size\": 16,\n",
    "                        \"save_model_every_n_epochs\": None,\n",
    "                        \"save_heatmaps_n_epochs\": 1,\n",
    "                        \"evaluate_n_epochs\": 1,\n",
    "                        \"test_batch_size\": 8,\n",
    "                        \"device\": \"cuda:0\",\n",
    "                        \"input_size\": 256,\n",
    "                        \"model_description\": \"{algo_name} model\", # description saved to each run from the dictionary - DIFFERENT to run_description in the cmd, which is the description attached to all the runs in a given config file - use no more than 20 characters - used in the results directory name\n",
    "                        \"model_long_description\": \"\", \n",
    "                        \"save_metric_meta_data\": False, # whether the metric data is saved alongside the metric results, setting as True will results in a lot of physical memory consumption\n",
    "                        \"wandb\": True,})\n",
    "\n",
    "    dataset_list = ['mvtec_bottle',]\n",
    "\n",
    "    metrics = [\"all\"]\n",
    "    ```\n",
    "6. Run:\n",
    "    ```\n",
    "    python3 run.py --config configs/{algo_name}/run_1.py --run_description \"new algorithm\" --device \"cuda:0\" --wandb 1\n",
    "    ```\n",
    "7. View the results view Wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
